{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# PYTHON数据管理\n",
    "[pandas官网](http://pandas.pydata.org/)\n",
    "\n",
    "pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with **“relational” or “labeled” data** both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal.\n",
    "\n",
    "panda 与SQL在很多地方都很相似，具体的对比可以参考[该链接](http://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PANDAS的功能**\n",
    "* 能够很好的处理missing value(NaN)\n",
    "* 可以对二维甚至高维的数据对象进行插入和删除\n",
    "* 支持将其它python数据结构简单快捷的转变为DataFrame\n",
    "* 支持分组计算group by \n",
    "* 支出数据重塑与数据透视表\n",
    "* 支持智能的基于标签的切片，索引选取等数据操作\n",
    "* 支持多个数据集的组合操作：join与merge\n",
    "* 支持从多个渠道读取文本数据\n",
    "* 支持时间序列time-series操作\n",
    "* 支持可视化数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "## 文件读取\n",
    "\n",
    "在之前的I/O章节中给我们学习了使用open函数来打开文件，read函数用来读取数据。 但是读取进来的数据都是str的格式，非常不方便我们进行分析。 pandas提供了read_csv函数可以将文件按照固定的格式进行读取，函数能够自动解析数据类型，添加列名与索引等很多功能，能够以结构化的dataframe形式存储数据。\n",
    "\n",
    "一些注意点：\n",
    "1. 不要尝试去读取excel文件，最好使用通用的csv或者txt格式\n",
    "2. 注意编码问题，使用encoding参数\n",
    "3. 注意处理报错行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pandas \n",
    "import numpy as np\n",
    "print(pandas.__version__) # 检查版本，如果太低请在终端使用 conda update pandas 命令进行升级"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读文件**\n",
    "```python\n",
    "pd.read_csv\n",
    "pd.read_excel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\feyman\\\\Documents\\\\2019SOTON课程\\\\2019年开学季\\\\pandas\\\\NBAPlayers.txt\",sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_excel(\"movie.xlsx\",sheet_name=0) #不推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写文件**\n",
    "```python\n",
    "df.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.to_csv(\"movie_1.csv\",sep = '\\t',index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## DataFrame 与 Series\n",
    "\n",
    "dataframe是二维结构化数据，series是一维数据。 dataframe有一个或者多个series组成，dataframe的一行或者一列就是一个series。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series的创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series** is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n",
    "\n",
    "**Series是能够存储任意数据类型的一维标签数组**\n",
    "\n",
    "```python\n",
    "s = pd.Series(data, index=index)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, data can be many different things:\n",
    "\n",
    "* a Python dict\n",
    "* an ndarray\n",
    "* a scalar value (like 5)\n",
    "\n",
    "The passed index is a list of axis labels. Thus, this separates into a few cases depending on what data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# From dict\n",
    "a = {\"name\":\"xiaoming\",\"age\":18,\"sex\":\"male\"}\n",
    "pd.Series(a,name='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# From scala\n",
    "pd.Series(5,index=list(\"abcdef\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b = [1,2,3,4,5,6]\n",
    "s1 = pd.Series(b,index = list(\"abcdef\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame的创建\n",
    "\n",
    "**DataFrame** is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object. Like Series, DataFrame accepts many different kinds of input:\n",
    "\n",
    "**DataFrame是拥有不同类型列的二维标签数据结构。你可以看作类似于EXCEL工作簿或者SQL表或者是由Series组成的字典。**\n",
    "\n",
    "* Dict of 1D ndarrays, lists, dicts, or Series\n",
    "* 2-D numpy.ndarray\n",
    "* Structured or record ndarray\n",
    "* A Series\n",
    "* Another DataFrame\n",
    "\n",
    "Along with the data, you can optionally pass index (row labels) and columns (column labels) arguments. If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame. Thus, a dict of Series plus a specific index will discard all data not matching up to the passed index.\n",
    "\n",
    "If axis labels are not passed, they will be constructed from the input data based on common sense rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a = {\"name\":[\"xiaoming\",\"xiaohong\",\"xiaogang\"],\"age\":[12,13,14]}\n",
    "\n",
    "pd.DataFrame(data = a,index = list('abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b = [\n",
    "     [1,2,3,4],\n",
    "     ['a','b','c','d']\n",
    "    ]\n",
    "\n",
    "pd.DataFrame(b,columns=list(\"ABCD\"),index= list('ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a = {\"name\":\"xiaoming\",\"age\":18,\"sex\":\"male\"}\n",
    "s1 = pd.Series(a)\n",
    "\n",
    "df_ = pd.DataFrame(s1,columns = ['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 常用的操作\n",
    "\n",
    "pandas对dataframe与series提供了丰富的操作方法，我们在次列出最为常用的一些。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### 查看属性\n",
    "1. columns\n",
    "2. index\n",
    "3. dtypes\n",
    "4. shape\n",
    "5. size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.index\n",
    "df.dtypes\n",
    "df.shape\n",
    "df.size\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "27454/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法使用\n",
    "1. head\n",
    "2. tail\n",
    "3. rename\n",
    "4. replace\n",
    "5. unique()\n",
    "6. value_counts()\n",
    "6. sort_values\n",
    "7. describe\n",
    "8. max/min/sum/mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"height\":\"Height\",\"weight\":\"Weight\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({\"Player\":{\"Curly Armstrong\":\"xiao\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = ['collage','Height'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df['birth_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据选取/添加/删除**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择列数据\n",
    "# df['Player']\n",
    "\n",
    "# df[['Player','Height']]\n",
    "df.Player # 不推荐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 增加一列\n",
    "df[\"class\"] = 1\n",
    "df['class']\n",
    "df.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "条件筛选：\n",
    "height >= 200 或者height <= 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Height'] >= 200) | (df['Height'] <= 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df['Height'] >= 200) | (df['Height'] <=170)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除\n",
    "del df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.sum(axis = 0)\n",
    "df.sum(axis = 1)\n",
    "df.sum() # 默认是 axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# somethong different\n",
    "\n",
    "import numpy as np \n",
    "a = np.array([[1,2,3,4,5,56],[3,4,5,1,7,3],[29,3,1,6,2,0]])\n",
    "\n",
    "np.sum(a,axis = 1)\n",
    "np.sum(a,axis = 0)\n",
    "np.sum(a) # 全部求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Missing value\n",
    "\n",
    "\n",
    "pandas使用numpy.nan来代表缺失值。缺失值不代表没有值，它本身就是某种类型的值。PYTHON中一般用None代表没有值，这与nan是两回事。缺失值不会被程序计算。处理的方式：\n",
    "1. 删除含有缺失值的行\n",
    "2. 填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = pd.Series([1,3,np.nan,10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测缺失值，返回布尔值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['birth_city'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除与填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除缺失值的行\n",
    "df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame([[np.nan, 2, np.nan, 0], [3, 4, np.nan, 1],\n",
    "                    [np.nan, np.nan, np.nan, 5]],\n",
    "                  columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(axis = 1,how = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(axis = 0,subset=['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值\n",
    "df.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({\"birth_city\":\"other\",\"birth_state\":\"something\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fillna(method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan <= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 文本数据\n",
    "dataframe与series中经常有文本格式的数据存在，pandas提供了良好的工具用来处理这些文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba ', ' Baca', 'CABA ', 'dog', 'cat'])\n",
    "s.str.strip() # 去除空格\n",
    "s.str.upper() # 转换成大写\n",
    "\n",
    "s[s.str.strip().str.endswith(\"a\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个很常用的场景就是当你的index或者column名称前后包含了空格的时候，你可以用str的方法剔除这些空格，从而避免不必要的麻烦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a = {\"name \":[\"xiaoming\",\"xiaohong\",\"xiaogang\"],\" age\":[12,13,14]}\n",
    "test = pd.DataFrame(data = a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#test['age'] # ERROR\n",
    "test.columns = test.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test['age'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting and Replacing String\n",
    "split方法用于根据某个分隔符对字符进行分割，返回一个列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['Player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['Player'].str.split(\" \") # 姓和名进行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用get方法获取指定位置的元素\n",
    "df['Player'].str.split(\" \").str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用expand方法\n",
    "df['Player'].str.split(\" \",expand = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index with .str**\n",
    "\n",
    "使用[]对字符串的位置进行索引选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Player'].str[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**[点击此处查看：str全部的可以用函数](http://pandas.pydata.org/pandas-docs/stable/text.html#method-summary)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类数据\n",
    "\n",
    "分类数据对应的是统计学中的分类变量：拥有一些有限的值。比如说性别，类型等等。 分类的数据可以有序列性属性，但是不支持数值类型的操作。\n",
    "\n",
    "常用的场景如下：\n",
    "1. 将一个只拥不是很多值的字符串变量转换成分类变量可以节省内存\n",
    "2. 分类变量可以让数据有逻辑排序而不是词汇（词典）的排序，比如 One/two/three\n",
    "3. 和其它Python库交互时，它会被当做分类变量处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建分类特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series的创建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 设定dtype为category\n",
    "s = pd.Series([\"a\", \"b\", \"c\", \"a\"], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换已有的数据类型\n",
    "df = pd.DataFrame({\"A\": [\"a\", \"b\", \"c\", \"a\"]})\n",
    "\n",
    "df[\"B\"] = df[\"A\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过pandas.Categorical 对象进行创建\n",
    "raw_cat = pd.Categorical([\"a\", \"b\", \"c\", \"a\"], categories=[\"b\", \"c\", \"d\",\"a\"],\n",
    "                         ordered=True)\n",
    "\n",
    "s = pd.Series(raw_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [\"a\", \"b\", \"c\", \"a\"]})\n",
    "\n",
    "df['B'] = raw_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame的创建**\n",
    "\n",
    "和之前series创建类似，不过dataframe中可以批量的将列转换格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建设定\n",
    "df_cat = pd.DataFrame({'A': list('abca'), 'B': list('bccd')}, dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换\n",
    "df['collage'] = df['collage'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 控制分类值行为:CategoricalDtype\n",
    "\n",
    "\"category\"默认了分类值的行为：\n",
    "* 类别从数据中继续进行推断\n",
    "* 没有排序的性质"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "s = pd.Series(['a','b','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type  = CategoricalDtype(categories=['b','c','d'],ordered=True)\n",
    "\n",
    "s.astype(cat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个分类的类别描述如下：\n",
    "* categories：一个唯一值的序列并且没有缺失值\n",
    "* ordered: 是否排序，布尔类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalDtype(categories=['b','c','d'],ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalDtype(categories=['b','c','d'],ordered=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类值的描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collage'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理分类变量\n",
    "分类数据拥有分类与排序的特征：包含了分类值展示以及值之间是否是有序的。我们可以通过 s.cat.categories 与 s.cat.ordered 进行操作。如果你没有人为的设定类别与排序信息，它们会被自动推断\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collage'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"a\", \"b\", \"c\", \"a\"], dtype=\"category\")\n",
    "s.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categories 和 方法 unique()返回的值是不一样的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list('babc')).astype(CategoricalDtype(list('abcd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加\n",
    "s = s.cat.add_categories([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除\n",
    "s = s.cat.remove_categories([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除没用的类别值\n",
    "s.cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新设定类别值\n",
    "s.cat.set_categories([\"a\", \"b\", \"c\", \"f\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type = CategoricalDtype(categories=['one','two','three'],ordered=True)\n",
    "\n",
    "s = pd.Series(['one','three','one','two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 索引选取\n",
    "\n",
    "根据某种条件筛选出数据的子集！\n",
    "\n",
    "Object selection has had a number of user-requested additions in order to support more explicit location based indexing. Pandas now supports three types of multi-axis indexing.\n",
    "\n",
    "* **.loc**  is primarily label based, but may also be used with a boolean array. .loc will raise KeyError when the items are not found. Allowed inputs are:\n",
    "\n",
    "**loc主要基于标签，但也可以与布尔数组一起使用。如果标签不存在，那么程序会报错：keyError**\n",
    "\n",
    "    * A single label, e.g. 5 or 'a', (note that 5 is interpreted as a label of the index. This use is not an integer position along the index)\n",
    "    \n",
    "    单个标签，比如 5 或者 'a'\n",
    "    \n",
    "    * A list or array of labels ['a', 'b', 'c']\n",
    "    \n",
    "    一系列的标签\n",
    "\n",
    "    * A slice object with labels 'a':'f' (note that contrary to usual python slices, both the start and the stop are included, when present in the index! - also see Slicing with labels)\n",
    "    \n",
    "    切片标签\n",
    "\n",
    "    * A boolean array\n",
    "    \n",
    "    布尔数组\n",
    "\n",
    "    * A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)\n",
    "\n",
    "\n",
    "\n",
    "* **.iloc**   is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with python/numpy slice semantics). Allowed inputs are:\n",
    "\n",
    "iloc主要基于整数位置，也可也使用布尔类型数组。 如果索引超出范围，iloc程序会报错IndexError.\n",
    "\n",
    "    * An integer e.g. 5\n",
    "    整数\n",
    "\n",
    "    * A list or array of integers [4, 3, 0]\n",
    "    一系列的整数\n",
    "    \n",
    "    * A slice object with ints 1:7\n",
    "    切片整数\n",
    "    \n",
    "    * A boolean array\n",
    "    布尔数组\n",
    "    \n",
    "    * A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于label.loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(np.random.randn(6), index=list('abcdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.loc['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.loc[['a','e','f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.loc[\"d\":'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.loc[s1>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame操作**\n",
    "\n",
    "DataFrame是二维数据，可以操控index与column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,['Player','height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[1,3,5],['Player','height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:5,['Player','height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['height'] >= 200,['Player','height']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于位置.iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.iloc[[0,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.iloc[0:3] # 与传统的切片是一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s1 > 0 # 必须是传统的array\n",
    "t.values\n",
    "s1.iloc[t.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.loc[[2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[[2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index(\"Player\") # 重新设置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1.loc[[\"Leo Barnhorst\",\"Ralph Beard\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1.iloc[[2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:10,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:10,['weight','height']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机选取数据\n",
    "\n",
    "A random selection of rows or columns from a Series or DataFrame with the sample() method. The method will sample rows by default, and accepts a specific number of rows/columns to return, or a fraction of rows.\n",
    "\n",
    "使用sample()方法对数据进行列或者行的随机选取，默认是对行进行选取。函数接受一个参数用来指定返回的数量或者百分比！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过控制axis对列进行抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n = 3,axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### 使用isin()\n",
    "\n",
    "该函数回返回一个布尔型向量，根据Series里面的值是否在给定的列表中。我们可以通过这个条件筛选出一列或者多列数据！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤 \"Chicago\",\"New York\"\n",
    "s = df['birth_city']\n",
    "s.isin([\"Chicago\",\"New York\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[s.isin([\"Chicago\",\"New York\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin()函数也可以用于index\n",
    "df.loc[s.index.isin([100,102])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于DataFrame我们可以使用dict进行处理，dict的key就是对应的column name.\n",
    "\n",
    "我们经常与all()或者any函数组合进行数据过滤选取\n",
    "* all 指定axis上的元素全部为True\n",
    "* any 指定axis上的元素至少一个为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df.isin({\"birth_city\":[\"Chicago\",\"New York\"],\"birth_state\":[\"Kentucky\",\"Indiana\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df_res.any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据过滤\n",
    "\n",
    "基于loc的强大功能，我们可以对数据做很多复杂的操作。第一个就是实现数据的过滤，类似于SQL里面的where功能\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取出height >= 180 ,weight >= 80的运动员数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['height']>=180) & (df['weight']>=80)]\n",
    "\n",
    "df[(df['height']>=180) & (df['weight']>=80)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "上面两种方法都可以，似乎没体现出.loc有什么优势。那么我们换个提问：\n",
    "\n",
    "创建一个新列，\n",
    "* 如果height >= 180, weight >=80, 值为 “high\"\n",
    "* 如果height<= 180 并且 height >=170, weight<= 80 并且 weight >=70 值为 ”msize\"\n",
    "* 其余的值为 \"small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "df.loc[(df['height'] >=180) & (df['weight'] >=80),\"flag\"] = \"high\"\n",
    "\n",
    "\n",
    "df.loc[((df['height'] <=180) & (df['height']>=170)) &  ((df['weight'] <=80) & (df['weight'] >=70)),\"flag\"] = \"msize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "df.loc[~(((df['height'] >=180) & (df['weight'] >=80)) |(((df['height'] <=180) & (df['height']>=170))&((df['weight'] <=80) & (df['weight'] >=70)))),\"flag\"] = \"small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['flag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query()方法\n",
    "\n",
    "使用表达式进行数据筛选.不接受外部变量！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"height >= 180 & weight >=80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用索引\n",
    "df.query(\"index >= 3500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_index()方法可以将一列或者多列设置为索引\n",
    "```python\n",
    "df.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index(keys = ['Player','collage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "reset_index()方法将索引放回数据框中的列，并且设置简单的整数索引\n",
    "```python\n",
    "df1.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(level=[0,1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where方法\n",
    "\n",
    "Selecting values from a Series with a boolean vector generally returns a subset of the data. To guarantee that selection output has the same shape as the original data, you can use the where method in Series and DataFrame.\n",
    "\n",
    "通过布尔类型的数组选取数据仅仅返回数据的子集。但是where()函数能够确保返回的结果和原数据的shape一样！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,4,6,4,2,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.where(s>2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重复数据 duplicate\n",
    "\n",
    "* duplicated  返回一个和行数相等的布尔数组，表明某一行是否是重复的\n",
    "* drop_duplicates 删除重复行\n",
    "\n",
    "通过keep参数来控制行的取舍\n",
    "* keep='first' (default): mark / drop duplicates except for the first occurrence.\n",
    "* keep='last': mark / drop duplicates except for the last occurrence.\n",
    "* keep=False: mark / drop all duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'a': ['one', 'one', 'two', 'two', 'two', 'three', 'four'],\n",
    "                    'b': ['x', 'y', 'x', 'y', 'x', 'x', 'x'],\n",
    "                    'c': np.random.randn(7)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.duplicated('a',keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(subset=['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(subset=['a','b'],keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiIndex\n",
    "\n",
    "层次索引可以允许我们操作更加复杂的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "           ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = list(zip(*arrays))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.random.randn(8), index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引选取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), index=index,columns = list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('bar', 'two')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('bar', 'two'), 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[('bar', 'two'), ('qux', 'one')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('bar',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(,'one')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可以使用切片(slicers)对多重索引进行操作**\n",
    "\n",
    "* 你可以使用任意的列表，元祖，布尔型作为Indexer\n",
    "* 可以使用sclie(None)表达在某个level上选取全部的内容，不需要对全部的level进行指定，它们会被隐式的推导为slice(None)\n",
    "* 所有的axis必须都被指定，意味着index和column上都要被显式的指明\n",
    "\n",
    "**正确的方式**\n",
    "```python\n",
    "df.loc[(slice('A1', 'A3'), ...), :]   \n",
    "```\n",
    "**错误的方式X**\n",
    "```python\n",
    "df.loc[(slice('A1', 'A3'), ...)]            \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(slice(None),'one'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# IndexSlice是一种更接近自然语法的用法，可以替换slice\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "df.loc[idx[:,'one'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[idx[:,'one'],idx['A','B',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**函数xs()可以让我们在指定level的索引上进行数据选取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs('one', level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与该方法等同\n",
    "df.loc[(slice(None),\"one\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多个level一起操作\n",
    "df.xs(('one', 'bar'), level=(1,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[idx[['bar','qux'],'one'],idx['A','B',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引排序**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 分组计算\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps\n",
    "\n",
    "* **Splitting** the data into groups based on some criteria\n",
    "* **Applying** a function to each group independently\n",
    "* **Combining** the results into a data structure\n",
    "Of these, the split step is the most straightforward. In fact, in many situations you may wish to split the data set into groups and do something with those groups yourself. In the apply step, we might wish to one of the following:\n",
    "\n",
    "\n",
    "* **Aggregation**: computing a summary statistic (or statistics) about each group. Some examples:\n",
    "\n",
    "    * Compute group sums or means\n",
    "    * Compute group sizes / counts\n",
    "    \n",
    "* **Transformation**: perform some group-specific computations and return a like-indexed. Some examples:\n",
    "\n",
    "    * Standardizing data (zscore) within group\n",
    "    * Filling NAs within groups with a value derived from each group\n",
    "    \n",
    "* **Filtration**: discard some groups, according to a group-wise computation that evaluates True or False. Some examples:\n",
    "\n",
    "    * Discarding data that belongs to groups with only a few members\n",
    "    * Filtering out data based on the group sum or mean\n",
    "    \n",
    "Some combination of the above: GroupBy will examine the results of the apply step and try to return a sensibly combined result if it doesn’t fit into either of the above two categories\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* _类似于SQL里面的group by 语句，不过pandas提供了更加复杂的函数方法_\n",
    "\n",
    "* _我们可以对index或者column进行分组，可以被一个元素，也可以是任意多个元素分组。分组后计算的方式否是一样的，无论是基于index还是column._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movie.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.director_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"director_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = df.groupby(['director_name','color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#grouped.size()\n",
    "#grouped.groups\n",
    "len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,group in grouped:\n",
    "    print(name)\n",
    "    print(len(group))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.set_index(\"director_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 索引分组\n",
    "g2 = df1.groupby(level=[\"director_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计计算\n",
    "1. 单个统计量计算 mean/sum/std\n",
    "2. 多个统计量计算\n",
    "3. 不同列应用不同统计量\n",
    "\n",
    "<span class=\"mark\">分组计算很重要的一点是：**我们的每一个统计函数都是作用在每一个group上，不是单个样本，也不是全部数据**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean()\n",
    "grouped.sum()\n",
    "grouped.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只针对某个特征进行计算\n",
    "grouped['duration'].sum()\n",
    "grouped['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[['duration','gross']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用agg函数进行多个统计量计算\n",
    "import numpy as np \n",
    "grouped[['duration','gross']].agg([np.mean,np.sum,\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同列应用不同统计量\n",
    "grouped.agg({\"duration\":np.mean,\"director_facebook_likes\":np.sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.fillna(0)\n",
    "grouped = df1.groupby(\"director_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = lambda s : (s-s.mean())/ s.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grouped[['num_critic_for_reviews','duration','director_facebook_likes']].transform(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grouped.filter(lambda g : g['duration'].mean() >= 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.filter(lambda g : len(g) >=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 表联结\n",
    "提供了类似于SQL的join接口，供我们进行多表组合。不同的是，pandas可以对index进行join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate\n",
    "```python\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "```\n",
    "\n",
    "* **objs** : a sequence or mapping of Series or DataFrame objects. If a dict is passed, the sorted keys will be used as the keys argument, unless it is passed, in which case the values will be selected (see below). Any None objects will be dropped silently unless they are all None in which case a ValueError will be raised.\n",
    "* **axis** : {0, 1, …}, default 0. The axis to concatenate along.\n",
    "* **join** : {‘inner’, ‘outer’}, default ‘outer’. How to handle indexes on other axis(es). Outer for union and inner for intersection.\n",
    "* **ignore_index** : boolean, default False. If True, do not use the index values on the concatenation axis. The resulting axis will be labeled 0, …, n - 1. This is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information. Note the index values on the other axes are still respected in the join.\n",
    "* keys : sequence, default None. Construct hierarchical index using the passed keys as the outermost level. If multiple levels passed, should contain tuples.\n",
    "* levels : list of sequences, default None. Specific levels (unique values) to use for constructing a MultiIndex. Otherwise they will be inferred from the keys.\n",
    "* names : list, default None. Names for the levels in the resulting hierarchical index.\n",
    "* verify_integrity : boolean, default False. Check whether the new concatenated axis contains duplicates. This can be very expensive relative to the actual data concatenation.\n",
    "* copy : boolean, default True. If False, do not copy data unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本数据\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                     'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                     index=[0, 1, 2, 3])\n",
    " \n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                     'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                     'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                     'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                      index=[4, 5, 6, 7])\n",
    " \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                     'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                     'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                     'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                     index=[8, 9, 10, 11])\n",
    "\n",
    "result = pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png\" width = \"400\" height = \"300\" alt=\"图片名称\" align=left />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#索引Join\n",
    "pd.concat([df1, df4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_axis1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内部join\n",
    "pd.concat([df1, df4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_axis1_inner.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略索引\n",
    "pd.concat([df1, df4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_ignore_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database-style DataFrame joining/merging\n",
    "\n",
    "merge函数用来对两张表进行join，非常类似于sql当中的表联结。 pandas里面不仅可以对columns进行Join,还可以对index进行join。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "```\n",
    "\n",
    "**SQL代码**\n",
    "```sql\n",
    "select a.*,b.*\n",
    "from \n",
    "(select * from table1) a \n",
    "left join \n",
    "(select * from table2) b\n",
    "on a.key1 = b.key2\n",
    "```\n",
    "-------------------------------------------------\n",
    "* left: A DataFrame object\n",
    "\n",
    "* right: Another DataFrame object\n",
    "\n",
    "* on: Columns (names) to join on. Must be found in both the left and right DataFrame objects. If not passed and left_index and right_index are False, the intersection of the columns in the DataFrames will be inferred to be the join keys\n",
    "\n",
    "* left_on: Columns from the left DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame\n",
    "\n",
    "* right_on: Columns from the right DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame\n",
    "\n",
    "* left_index: If True, use the index (row labels) from the left DataFrame as its join key(s). In the case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame\n",
    "\n",
    "* right_index: Same usage as left_index for the right DataFrame\n",
    "\n",
    "* how: One of 'left', 'right', 'outer', 'inner'. Defaults to inner. See below for more detailed description of each method\n",
    "\n",
    "* sort: Sort the result DataFrame by the join keys in lexicographical order. Defaults to True, setting to False will improve performance substantially in many cases\n",
    "\n",
    "* suffixes: A tuple of string suffixes to apply to overlapping columns. Defaults to ('_x', '_y').\n",
    "\n",
    "* copy: Always copy data (default True) from the passed DataFrame objects, even when reindexing is not necessary. Cannot be avoided in many cases but may improve performance / memory usage. The cases where copying can be avoided are somewhat pathological but this option is provided nonetheless.\n",
    "\n",
    "* indicator: Add a column to the output DataFrame called _merge with information on the source of each row. _merge is Categorical-type and takes on a value of left_only for observations whose merge key only appears in 'left' DataFrame, right_only for observations whose merge key only appears in 'right' DataFrame, and both if the observation’s merge key is found in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "outputs": [],
   "source": [
    "# 在一个主键上进行join\n",
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                      'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                      'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "\n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                       'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                       'D': ['D0', 'D1', 'D2', 'D3']})\n",
    " \n",
    "\n",
    "result = pd.merge(left, right, on='key')\n",
    "pd.merge(left, right, left_on='key',right_on = 'key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "![r1](http://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "outputs": [],
   "source": [
    "# 在多个主键上Join\n",
    "left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                      'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                      'B': ['B0', 'B1', 'B2', 'B3']})\n",
    " \n",
    "\n",
    "right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                       'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                       'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                       'D': ['D0', 'D1', 'D2', 'D3']})\n",
    " \n",
    "\n",
    "result = pd.merge(left, right, on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "![r2](http://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_multiple.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, how='left', on=['key1', 'key2'],indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "![r3](http://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_left.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, how='right', on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, how='outer', on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "![r4](http://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_outer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**joining on index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                      'B': ['B0', 'B1', 'B2']},\n",
    "                     index=['K0', 'K1', 'K2'])\n",
    " \n",
    "\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                       'D': ['D0', 'D2', 'D3']},\n",
    "                      index=['K0', 'K2', 'K3'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_index_outer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                      'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                      'key': ['K0', 'K1', 'K0', 'K1']})\n",
    " \n",
    "\n",
    "right = pd.DataFrame({'C': ['C0', 'C1'],\n",
    "                       'D': ['D0', 'D1']},\n",
    "                      index=['K0', 'K1'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, left_on='key', right_index=True,\n",
    "                   how='left');\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_key_columns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 数据透视与重塑(pivot table and reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重塑 reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_pivot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
    "                       'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                       'baz': [1, 2, 3, 4, 5, 6]})\n",
    "\n",
    "df.pivot(index='foo', columns='bar', values='baz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最常用的地方是时间序列数据：\n",
    "\n",
    "* date:代表日期\n",
    "* group：代表销售小组\n",
    "* sells：销售小组的业绩\n",
    "\n",
    "index是日期用来表示每一条观测值，columns就是唯一的变量！\n",
    "\n",
    "*A better representation would be where the columns are the unique variables and an index of dates identifies individual observations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "today = datetime.now().date()\n",
    "\n",
    "date = [today - timedelta(days = i)  for i in range(5)] * 6\n",
    "\n",
    "group = ['A']*5 + ['B'] * 5 + ['C']*5 + ['D'] * 5 +['E']*5 +['F']*5\n",
    "sells = np.random.randint(1000,100000,size = (30,)).tolist()\n",
    "\n",
    "\n",
    "data = {\"date\":date,\"group\":group,\"sells\":sells}\n",
    "\n",
    "df_pivot = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.sort_values(['group','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.pivot(index='date',columns='group',values='sells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果没有指定values参数，程序会计算出所有可被计算的列，并在最上方形成多层索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['cumsells'] = df_pivot['sells']*2+1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.pivot(index='date',columns='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** \n",
    "\n",
    "pivot() will error with a ValueError: Index contains duplicate entries, cannot reshape if the index/column pair is not unique. In this case, consider using pivot_table() which is a generalization of pivot that can handle duplicate values for one index/column pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stack()与 unstack()** 函数都是用于多重索引的\n",
    "\n",
    "* stack()：column转换成index\n",
    "\n",
    "* unstack():index转换成column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "                      'foo', 'foo', 'qux', 'qux'],\n",
    "                     ['one', 'two', 'one', 'two',\n",
    "                      'one', 'two', 'one', 'two']]))\n",
    " \n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "\n",
    "df_mul = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mul.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "会形成多少行呢？\n",
    "\n",
    "* m : 行数\n",
    "* n: 列数\n",
    "* 总数量：m * n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_unstack.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_unstack_1.png)\n",
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_unstack_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_melt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "某些列设置为标记变量，其它的列被设置为衡量变量。函数会自动生成两列：“variable” and “value”，我们也可以通过 var_name 和 value_name 两个参数自定义列名。\n",
    "```python\n",
    "pd.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.melt(id_vars = ['Player','collage'],value_vars=['height','weight']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 透视表 pivot table\n",
    "\n",
    "**pivot_table** 提供了类似于EXCEL数据透视表的功能，重点的参数如下:\n",
    "\n",
    "* data: A DataFrame object\n",
    "* values: a column or a list of columns to aggregate\n",
    "* index: a column, Grouper, array which has the same length as data, or list of them. Keys to group by on the pivot table index. If an array is passed, it is being used as the same manner as column values.\n",
    "* columns: a column, Grouper, array which has the same length as data, or list of them. Keys to group by on the pivot table column. If an array is passed, it is being used as the same manner as column values.\n",
    "* aggfunc: function to use for aggregation, defaulting to numpy.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**crosstab** 用于计算两个以上的因子的cross-tabulation. 默认的是计算因子之间的频率，除非指定了其它数组或者函数进行计算\n",
    "\n",
    "* index: array-like, values to group by in the rows\n",
    "* columns: array-like, values to group by in the columns\n",
    "* values: array-like, optional, array of values to aggregate according to the factors\n",
    "* aggfunc: function, optional, If no values array is passed, computes a frequency table\n",
    "* rownames: sequence, default None, must match number of row arrays passed\n",
    "* colnames: sequence, default None, if passed, must match number of column arrays passed\n",
    "* margins: boolean, default False, Add row/column margins (subtotals)\n",
    "* normalize: boolean, {‘all’, ‘index’, ‘columns’}, or {0,1}, default False. Normalize by dividing all values by the sum of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['director_name'],df['color'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pd.pivot_table(df,values = ['duration'],columns = ['director_name'],index=['color'],aggfunc=[np.sum],margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## [一键数据分析](https://github.com/pandas-profiling/pandas-profiling)\n",
    "\n",
    "**注意** 该工具包存在BUG，不能确保所有电脑的jupyter都能安装上，至今官方也没有给与正确的修复方式！！！\n",
    "\n",
    "https://github.com/pandas-profiling/pandas-profiling\n",
    "\n",
    "安装命令：pip install pandas-profiling\n",
    "\n",
    "---------------------\n",
    "\n",
    "Generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n",
    "\n",
    "For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n",
    "\n",
    "* Essentials: type, unique values, missing values\n",
    "* Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n",
    "* Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n",
    "* Most frequent values\n",
    "* Histogram\n",
    "* Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n",
    "* Missing values matrix, count, heatmap and dendrogram of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "df.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Cheetsheet\n",
    "![](https://ftp.bmp.ovh/imgs/2019/09/1395463d95aecb04.jpg)\n",
    "![](https://ftp.bmp.ovh/imgs/2019/09/25fe9be6f9c6affb.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "284px",
    "left": "1068px",
    "right": "93.8859px",
    "top": "349px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
